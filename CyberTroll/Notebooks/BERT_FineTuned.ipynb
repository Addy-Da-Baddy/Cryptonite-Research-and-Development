{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dasad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\dasad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dasad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dasad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\dasad\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import nlpaug.augmenter.word as naw\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize stemmer and lemmatizer\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "df = pd.read_csv('offensive.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='class', data=df, palette='muted')\n",
    "plt.title('Distribution of Comments')\n",
    "plt.xlabel('Annotation (0 = Hate Speech, 1 = Offensive, 2 = Neither)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before balancing:\n",
      "       Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
      "0               0      3            0                   0        3      2   \n",
      "1               1      3            0                   3        0      1   \n",
      "2               2      3            0                   3        0      1   \n",
      "3               3      3            0                   2        1      1   \n",
      "4               4      6            0                   6        0      1   \n",
      "...           ...    ...          ...                 ...      ...    ...   \n",
      "24778       25291      3            0                   2        1      1   \n",
      "24779       25292      3            0                   1        2      2   \n",
      "24780       25294      3            0                   3        0      1   \n",
      "24781       25295      6            0                   6        0      1   \n",
      "24782       25296      3            0                   0        3      2   \n",
      "\n",
      "                                                   tweet  \\\n",
      "0      !!! RT @mayasolovely: As a woman you shouldn't...   \n",
      "1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
      "2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
      "3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
      "4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
      "...                                                  ...   \n",
      "24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...   \n",
      "24779  you've gone and broke the wrong heart baby, an...   \n",
      "24780  young buck wanna eat!!.. dat nigguh like I ain...   \n",
      "24781              youu got wild bitches tellin you lies   \n",
      "24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...   \n",
      "\n",
      "                                       processed_content  \n",
      "0      mayasolovely a a woman you should not complain...  \n",
      "1      mleew17 boy dat coldtyga dwn bad for cuffin da...  \n",
      "2      urkindofbrand dawg you ever fuck a bitch and s...  \n",
      "3                       vivabased she look like a tranny  \n",
      "4      shenikaroberts the shit you hear about me migh...  \n",
      "...                                                  ...  \n",
      "24778  yous a muthafin lie 8220lifeasking 20pearls co...  \n",
      "24779  you have gone and broke the wrong heart baby a...  \n",
      "24780  young buck want to eat dat nigguh like i are n...  \n",
      "24781                        youu got wild bitch you lie  \n",
      "24782  ruffled ntac eileen dahlia beautiful color com...  \n",
      "\n",
      "[24783 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import contractions\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import spacy\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "\n",
    "# Load SpaCy model for NER\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Initialize lemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(text):\n",
    "    # 1. Expand contractions\n",
    "    text = contractions.fix(text)\n",
    "    \n",
    "    # 2. Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 3. Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\.\\S+', '', text)\n",
    "    \n",
    "    # 4. Remove special characters and punctuation\n",
    "    text = re.sub(f\"[{re.escape(string.punctuation)}]\", \"\", text)\n",
    "    \n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    \n",
    "    # 4. Remove all instances of \"rt\" (case-insensitive)\n",
    "    text = re.sub(r'\\brt\\b', '', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 5. Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # 6. Lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # 7. NER (Named Entity Recognition) - Remove named entities\n",
    "    doc = nlp(\" \".join(tokens))\n",
    "    tokens = [token.text for token in doc if token.ent_type_ == \"\"]\n",
    "    \n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing to the dataframe\n",
    "df['processed_content'] = df['tweet'].apply(preprocess)\n",
    "\n",
    "print(\"Before balancing:\")\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After balancing:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_content</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mayasolovely a a woman you should not complain...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mleew17 boy dat coldtyga dwn bad for cuffin da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urkindofbrand dawg you ever fuck a bitch and s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vivabased she look like a tranny</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>shenikaroberts the shit you hear about me migh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57565</th>\n",
       "      <td>ghetto bird can not fly away from my hood</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57566</th>\n",
       "      <td>firecashman i do not want arod back</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57567</th>\n",
       "      <td>petehelm yeah but sting wa already a proven dr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57568</th>\n",
       "      <td>charlie4927 hi charlie have</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57569</th>\n",
       "      <td>review</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57570 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       processed_content  class\n",
       "0      mayasolovely a a woman you should not complain...      2\n",
       "1      mleew17 boy dat coldtyga dwn bad for cuffin da...      1\n",
       "2      urkindofbrand dawg you ever fuck a bitch and s...      1\n",
       "3                       vivabased she look like a tranny      1\n",
       "4      shenikaroberts the shit you hear about me migh...      1\n",
       "...                                                  ...    ...\n",
       "57565          ghetto bird can not fly away from my hood      2\n",
       "57566                firecashman i do not want arod back      2\n",
       "57567  petehelm yeah but sting wa already a proven dr...      2\n",
       "57568                        charlie4927 hi charlie have      2\n",
       "57569                                             review      2\n",
       "\n",
       "[57570 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 8. Balance dataset using RandomOverSampler\n",
    "X = df[['processed_content']]\n",
    "y = df['class']\n",
    "\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "\n",
    "# Combine resampled data into a new dataframe\n",
    "df= pd.concat([X_resampled, y_resampled], axis=1)\n",
    "\n",
    "print(\"\\nAfter balancing:\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAswAAAImCAYAAABHDtz+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAABf2UlEQVR4nO3deVxU9eL/8fegIhjiFopfTSNpQFQQA0VNMdxuudzIylLMLdMsvFppueRyS3Erc0lNxSWXUHPJa3VL7Za5RGpapqAXcykVMVMJZef8/vDHXEfgiIgy5uv5eMzjwZzP53zO5xz4DO858zlnLIZhGAIAAACQL6eS7gAAAADgyAjMAAAAgAkCMwAAAGCCwAwAAACYIDADAAAAJgjMAAAAgAkCMwAAAGCCwAwAAACYIDADgAlH+G4nR+gDih+/V+DOQWAGcMfq0aOHfHx8bA9fX18FBgbqiSee0NKlS5WdnW1XPywsTG+88Uah29+yZYtef/3169Z74403FBYWVuTtFCQjI0NRUVH617/+VeC2HMHUqVPVpEkTNWzYUOvXry+wXk5OjlavXq3u3burSZMmatSokcLDw/Xhhx8qIyPj9nW4hCUnJ+v111/X7t27S7orAAqpdEl3AABuhp+fn8aMGSNJys7O1sWLF/XNN99owoQJ2rNnj6ZNmyaLxSJJmjVrltzc3Ard9uLFiwtVb+DAgXruueduuO/Xk5SUpMWLFysqKuqWb6uoDh8+rPnz5+vpp5/W3//+dz3wwAP51ktNTdWAAQP0448/6tlnn9Xzzz+vMmXKKDY2VlOnTtU333yjOXPmyNnZ+Tbvwe0XFxen9evX64knnijprgAoJAIzgDuam5ubGjZsaLcsLCxMXl5eioqKUlhYmDp37izpSri+FWrVqnVL2i3pbRXGhQsXJEkdOnRQUFBQgfWioqL0ww8/aOnSpXa/r4cfflh+fn4aPHiwli9frt69e9/iHgPAjWNKBoC/pB49eqhq1aqKiYmxLbt2qsRnn32mzp07y9/fXyEhIXrttdeUlJRkW//777/X999/Lx8fH8XGxio2NlY+Pj6KiYnRI488ombNmmnbtm35TpPIzMzU22+/reDgYAUHB+v111/XH3/8YSvPb53ffvtNPj4+Wrt2rX777Te1bt1akjR8+HBb3WvXy87O1vLly9WpUyf5+/urVatWmjp1qtLT0+221atXL61Zs0bt27dX/fr11blzZ33zzTfXPY6fffaZnnjiCQUGBqp58+YaPXq0Ll68KEmaOXOmevToIUnq2bNngVNF/vjjD61Zs0ZdunTJ8+ZGkh599FH17dtXnp6etmV//vmnoqKi1KZNGzVo0EAdO3bUxx9/bLdeWFiYZs2apaioKDVp0kSBgYF69dVXdenSJc2bN08tW7bUQw89pMjISJ0/f/6m15Ok1atXq0OHDqpfv75atWqlmTNnKisrq9DHOjY21vYJwXPPPWc7fr/++qtefPFFNWnSRAEBAeratWuhfj8Abg/OMAP4SypVqpSaNm2qzz77TFlZWSpd2v7lbs+ePXrttdc0cOBABQcHKzExUVOmTNGrr76qpUuXasyYMRo6dKgkacyYMfL29taBAwckSdOmTdO4ceOUnp6uhg0bauPGjXm2//nnn8vf318TJ07UH3/8oalTp+r48eN2Ad5M1apVNWvWLL388st68cUX1a5du3zrjR49WuvXr9fzzz+vxo0b6+DBg3r//fcVFxenBQsW2Kaj/Pzzz0pKStKgQYPk5uam6dOna9CgQdq6dasqVKiQb9uzZ8/W9OnT1a1bNw0ZMkS//vqrpk+frn379mnVqlV66qmnVLlyZf3zn//U6NGjFRgYmG87O3fuVFZWlh555JEC93fYsGG2n9PS0tStWzf9/vvvioyM1H333afNmzdr5MiR+v333zVgwABb3UWLFqlZs2aaNm2a9u/fr3fffVcHDhxQtWrV9NZbb+no0aOaPHmy7r33XtvUnaKu98EHH2jatGmKiIjQ8OHDFRcXp5kzZ+r06dOaMGGCrW2zY12vXj2NHj3adsyaNGminJwc9e/fXx4eHpo8ebJKly6tDz/8UAMHDtRnn32m2rVrF3jcANweBGYAf1n33nuvMjMzdeHCBd177712ZXv27FHZsmXVr18/lS1bVpJUsWJF7d+/X4ZhyNvb2zbf+dqzos8884z+9re/mW7b3d1dCxYssLVRqVIlvfTSS9q2bZsefvjh6/bd2dlZdevWlXRlGkZ+00kSEhL08ccfa/DgwXrxxRclSc2bN1fVqlU1bNgwbd26VaGhoZKunLFdu3atbUpHuXLlFBERoe+++07t27fP0/bFixc1Z84cPfXUU3ZB02q1qnv37lq7dq26desmb29vSZK3t3eBU14SExMlSTVr1rzufkvS2rVrdfjwYa1YsUIPPfSQJKlFixbKysrS7Nmz9cwzz6hixYqSpHvuuUfTpk1T6dKl1axZM61bt05JSUlavXq1ypcvr9DQUH333Xf64Ycf7LZxo+v9+eefmjNnjrp27apRo0ZJujKdpGLFiho1apR69+6tBx98sFDH+upj5u3trbNnz+rIkSMaMGCA7ffl7++vWbNm2X1SAKDkMCUDwF9e7lnWqwUHBystLU2dOnXStGnTtGfPHj388MN6+eWX861/NR8fn+tuMzQ01O4Cw7CwMJUpU0Y7duy48R0owPfffy9J6tSpk93yDh06qFSpUoqNjbUtq1y5st3859zpD6mpqfm2vW/fPmVkZORpOygoSDVq1LBr+3qcnK78q8nJySlU/e+//141atSwheVcnTt3Vnp6un788UfbMn9/f7tPDzw8PPTAAw+ofPnytmUVK1bUn3/+adfWja63d+9epaamKiwsTFlZWbZH7jSU7du329a70WN97733ytvbW2+++abeeOMNffbZZzIMQ8OHD5fVar3O0QJwOxCYAfxlnTlzRi4uLrazkVcLDAzUvHnzdN999yk6OlrdunVTaGiolixZct12q1Spct06157RdnJyUsWKFZWcnFzo/l9P7lxiDw8Pu+WlS5dWpUqV7EKiq6urXZ3cNwUFhdjctq/dj9xl1wZQMzVq1JAknTp1qsA6Z8+etc0FvnjxYoHblWR3DPO768m1+5qfG10v9+LGF154QfXq1bM9mjVrJkm2ue/5tXO9Y22xWLRw4UKFh4fr22+/1ZAhQ9SsWTMNHjzYtl0AJYspGQD+krKzs/X999+rUaNGKlWqVL51WrRooRYtWig1NVXfffedPvzwQ02YMEENGzZUQEDATW3/2mCcnZ2t8+fP28K2xWLJc5/oy5cv39A2cucenz171m66Q2Zmps6fP69KlSoVpet2bf/++++qU6eOXdnZs2d13333FbqtkJAQlSlTRt98841tysG1+vfvr9TUVH3++eeqUKGCjh8/nqfO2bNnJemm9quo3N3dJV255/T999+fpzy/gH8jqlWrprFjx2rMmDGKj4/Xv//9b82fP18VKlTQuHHjbqptADePM8wA/pJiYmKUlJSkZ599Nt/ySZMm6cknn5RhGHJ1ddUjjzxi+5KS06dPS/rfVIKi2LFjh93dE7744gtlZWWpSZMmkq7MoT1//rzdHNVr59kWFPRzNW7cWJLsvthEkj799FNlZ2fnmdJwIwICAuTs7Jyn7d27d+vUqVNq1KhRodtyd3fXk08+qVWrVumnn37KU75x40YdOHBAf//73yVdmS5z8uRJ7dmzx67ehg0bVKZMGfn7+xdhj25OQECAypQpozNnzqhBgwa2R5kyZfTOO+/ot99+K3Rb1/5e9+7dq2bNmumnn36SxWJR3bp1NWTIEFmtVtv8bwAlizPMAO5oKSkp2rdvn6QrH3mfP39e27Zt08qVK9W5c+cC7y7RtGlTLVq0SG+88YY6d+6szMxMLViwQBUrVlRISIikK0Fv79692rlz5w3fwzn3Dg89evTQsWPH9O6776p58+Zq2rSpJOmRRx7R0qVLNWLECD311FP673//q4ULF9qFqdz5tDt37lSdOnXynPX29vZWeHi4Zs2apbS0NDVp0kRxcXGaNWuWmjRpohYtWtxQn69WsWJFvfDCC5o1a5bKlCmj1q1b67ffftP06dPl7e19w1+68corr2j//v3q2bOn7Zv+srKy9O2332rVqlVq2bKlnn/+eUnSE088oRUrVujll1/WoEGDdN999+mrr77SmjVr9PLLL9vO9t5OlSpV0vPPP6/p06crJSVFTZo00ZkzZzR9+nRZLBb5+voWuq3c3+vXX3+tChUqyM/PTy4uLho2bJgiIyN17733aseOHYqLi3OoL6kB7mYEZgB3tIMHD6pr166SrpwRrlKliry8vDRx4sQ8F6xdrWXLlpo6daoWLlxou9DvoYce0ocffmib89y9e3f9/PPP6tevn6KiolS1atVC9+vpp59WWlqaXnrpJTk7O6tTp04aOnSobT5r8+bN9frrr2vp0qX68ssvVa9ePc2aNUvPPPOMrQ03Nzf17t1bK1eu1Ndff213YVmu8ePHq3bt2lqzZo2io6NVtWpV9ejRQy+99NJNnSGXZAtvy5Yt0+rVq1WxYkX97W9/0+DBgws1T/hq7u7uWrp0qZYtW6bPPvtMMTExMgxDtWvX1vDhw/XUU0/ZLsJzdXXV0qVL9c4772jGjBlKSUnRAw88oPHjx+vJJ5+8qX26GYMHD5aHh4dWrFihBQsWqEKFCmratKleeeUVu4sFr+fBBx9Ux44dtXz5cn377bfauHGjFi5cqHfeeUfjx49XcnKy7r//fv3zn//k2wABB2ExDMMo6U4AAAAAjoo5zAAAAIAJAjMAAABggsAMAAAAmCAwAwAAACYIzAAAAICJEg/MFy5c0OjRo9WyZUs1atRIzz77rHbv3m0rj4uLU0REhBo2bKhWrVopOjrabv2cnBzNmDFDLVq0UEBAgPr06ZPnG6KKow0AAADcnUr8tnJ9+vTRuXPn9Oabb6py5cpasWKFVq9erbVr16py5cp69NFH1aZNG/Xu3Vv79u3TuHHjNGbMGHXp0kWSNGvWLK1YsUJRUVGqVq2apkyZol9//VUbN26Us7Ozzp8/f9Nt3Ki9e/fKMAyVKVOmWI8VAAAAikdmZqYsFosCAwOvW7dEA/Px48fVrl07ffTRR7avWTUMQ+3bt1eHDh3k4uKi5cuX66uvvrLd0P7dd9/Vl19+qX//+9/KyMhQSEiIhg4davv62+TkZLVo0UITJkxQhw4d9MEHH9x0Gzfqhx9+kGEYRQrbAAAAuPUyMjJksVhsGdRMiX7TX6VKlTRv3jzVr1/ftsxiscgwDF28eFE///yzgoODbUFXkkJCQvTBBx/o3LlzOnnypC5dumT7GlvpyrdJ+fn5adeuXerQoYN27959023cqNwzyw0aNLjhdQEAAHDr7d+/v9B1S3QOs7u7u0JDQ+3OxH7++ec6ceKEHn74YSUmJsrT09Nundyvpj116pQSExMlSdWrV89T5/Tp05JULG0AAADg7lWiZ5ivtWfPHo0YMUKtW7dWWFiYoqKi8kxrKFu2rCQpPT1dqampkpRvnYsXL0qS0tLSbrqNojAMQ5cvXy7y+gAAALh1DMOQxWIpVF2HCcybN2/Wa6+9poCAAL377ruSJBcXF2VkZNjVS09PlySVK1dOLi4ukq7MQcn9ObeOq6trsbVRFJmZmYqLiyvy+gAAALi1Cnu9mUME5mXLlmn8+PFq27atpk6dauu8p6enkpKS7OrmPq9WrZqysrJsy2rVqmVXx9fXt9jaKIoyZcrI29u7yOsDAADg1klISCh03RIPzCtWrNBbb72lHj16aMSIEXJy+t+06uDgYMXExCg7O1ulSpWSJO3cuVNeXl6qUqWKypcvLzc3N8XGxtrCbnJysg4ePKiIiIhia6MoLBaLypUrV+T1AQAAcOsUdjqGVMIX/R09elQTJkxQ27Zt1b9/f507d05nz57V2bNn9eeff6pLly5KSUnRyJEjlZCQoLVr12rJkiXq37+/pCun0SMiIjR16lRt2bJF8fHxGjJkiDw9PdW2bVtJKpY2AAAAcPcq0fswz507V9OmTcu3LDw8XBMnTtRPP/2k8ePH6+DBg/Lw8FCfPn3szvxmZ2fr3Xff1dq1a5WWlqbg4GCNHj1aNWvWtNUpjjZuRO5tSritHAAAgGO6kbxW4t/091dEYAYAAHBsN5LXSnRKBgAAAODoCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMN9BcnKMku4CYOdO+Zs0cnJKuguAnTvhbzLHcPw+4u5TUn+XpUtkqygSJyeL3v/4oE6evVzSXQFUw6OcXnrSr6S7USgWJyed/vQDZZw7VdJdAeRc5f9UvUP/ku7GdTlZnPTRwWVKunympLsCSJKqlqumZ/0iSmTbBOY7zMmzl3XsdEpJdwO442ScO6X0pOMl3Q3gjpJ0+YxOppws6W4AJY4pGQAAAIAJAjMAAABggsAMAAAAmCAwAwAAACYIzAAAAIAJAjMAAABggsAMAAAAmCAwAwAAACYIzAAAAIAJAjMAAABggsAMAAAAmCAwAwAAACYIzAAAAIAJAjMAAABggsAMAAAAmCAwAwAAACYIzAAAAIAJAjMAAABggsAMAAAAmCAwAwAAACYIzAAAAIAJAjMAAABggsAMAAAAmCAwAwAAACYIzAAAAIAJAjMAAABggsAMAAAAmCAwAwAAACYIzAAAAIAJAjMAAABggsAMAAAAmHCowDx79mz16NHD9rxHjx7y8fHJ97F+/XpJ0smTJ/MtX716ta2duLg4RUREqGHDhmrVqpWio6PttpuTk6MZM2aoRYsWCggIUJ8+fXT8+PHbss8AAABwbKVLugO5Fi9erBkzZig4ONi2bObMmcrMzLSrN2rUKJ04cUJt2rSRJB06dEhly5bV5s2bZbFYbPXKly8vSTp//rx69+6tNm3aaNy4cdq3b5/GjRunihUrqkuXLpKuBPWYmBhFRUWpWrVqmjJlivr166eNGzfK2dn5Vu86AAAAHFiJB+YzZ85o5MiR2rNnj7y8vOzKKlasaPd848aN2rZtm9auXSs3NzdJ0uHDh+Xl5aWqVavm2/6qVavk7OyssWPHqnTp0qpTp46OHz+u+fPnq0uXLsrIyNDChQs1dOhQhYaGSpKmTZumFi1aaNOmTerQoUPx7zQAAADuGCU+JePAgQOqUKGCNmzYoICAgALrXb58WZMnT1bPnj3l4+NjW37o0CF5e3sXuN7u3bsVHBys0qX/994gJCRER48e1blz5xQfH69Lly4pJCTEVu7u7i4/Pz/t2rXrJvcOAAAAd7oSP8McFhamsLCw69aLiYnRpUuX9OKLL9otP3z4sDw8PNStWzcdO3ZMtWvX1sCBA9WiRQtJUmJioqxWq906uWejT506pcTERElS9erV89Q5ffp0kffLMAxdvny5yOtfy2KxyNXVtdjaA4pLamqqDMMo6W4UiLEDR+XIY4dxA0dWXGPHMAy76bxmSjwwF0Z2draWLl2qbt262eYmS1JGRoaOHTsmV1dXDRs2TOXKldOGDRvUr18/LVq0SE2bNlVaWlqeechly5aVJKWnpys1NVWS8q1z8eLFIvc5MzNTcXFxRV7/Wq6urvLz8yu29oDicvToUds4ckSMHTgqRx47jBs4suIcO4W9Vu2OCMzff/+9Tp06paefftpuubOzs3bt2qXSpUvbdrh+/fo6cuSIoqOj1bRpU7m4uCgjI8NuvfT0dElSuXLl5OLiIulK+M79ObfOzby7LlOmjOlUkRtV2HdAwO3m5eXlsGfJJMYOHJcjjx3GDRxZcY2dhISEQte9IwLz5s2b5e/vr/vuuy9PWbly5fIss1qt2rZtmyTJ09NTSUlJduW5z6tVq6asrCzbslq1atnV8fX1LXKfLRZLvn0D/mr42BYoGsYOUDTFNXZu5I1hiV/0Vxh79uyxuygvV3x8vAIDA7V792675T///LPt7G5wcLD27Nmj7OxsW/nOnTvl5eWlKlWqyNfXV25uboqNjbWVJycn6+DBgwoKCrpFewQAAIA7hcMH5uzsbCUkJOS5cE+6cib5wQcf1Lhx47R7924dOXJEUVFR2rdvnwYMGCBJ6tKli1JSUjRy5EglJCRo7dq1WrJkifr37y/pyrSOiIgITZ06VVu2bFF8fLyGDBkiT09PtW3b9rbuKwAAAByPw0/JuHDhgjIzM/Pck1mSnJycNHfuXE2dOlWDBw9WcnKy/Pz8tGjRItut56pUqaIFCxZo/PjxCg8Pl4eHh4YNG6bw8HBbO4MGDVJWVpZGjRqltLQ0BQcHKzo6mi8tAQAAgGMF5okTJ+ZZVqVKFR06dKjAdSpXrqwJEyaYtuvv76+VK1cWWF6qVCkNHTpUQ4cOLXxnAQAAcFdw+CkZAAAAQEkiMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJhwqMA8e/Zs9ejRw27Z8OHD5ePjY/do2bKlrTwnJ0czZsxQixYtFBAQoD59+uj48eN2bcTFxSkiIkINGzZUq1atFB0dbVdemDYAAABwd3KYwLx48WLNmDEjz/JDhw5pwIAB2rZtm+2xfv16W/ns2bMVExOjt99+WytXrpTFYlG/fv2UkZEhSTp//rx69+6t+++/X2vWrFFkZKSmT5+uNWvWFLoNAAAA3L1KPDCfOXNGzz//vKZPny4vLy+7suzsbCUkJKhBgwby8PCwPSpXrixJysjI0MKFCxUZGanQ0FD5+vpq2rRpOnPmjDZt2iRJWrVqlZydnTV27FjVqVNHXbp0Ua9evTR//vxCtwEAAIC7V4kH5gMHDqhChQrasGGDAgIC7MqOHTum9PR01alTJ9914+PjdenSJYWEhNiWubu7y8/PT7t27ZIk7d69W8HBwSpdurStTkhIiI4ePapz584Vqg0AAADcvUpfv8qtFRYWprCwsHzLDh8+LIvFoiVLlmjr1q1ycnJSaGioBg8erPLlyysxMVGSVL16dbv1qlatqtOnT0uSEhMTZbVa85RL0qlTpwrVRlEYhqHLly8Xef1rWSwWubq6Flt7QHFJTU2VYRgl3Y0CMXbgqBx57DBu4MiKa+wYhiGLxVKouiUemM3897//lZOTk2rUqKG5c+fq+PHjmjRpkg4fPqwlS5YoNTVVkuTs7Gy3XtmyZXXx4kVJUlpaWr7lkpSenl6oNooiMzNTcXFxRV7/Wq6urvLz8yu29oDicvToUds4ckSMHTgqRx47jBs4suIcO9fmv4I4dGCOjIxUr1695O7uLkmyWq3y8PBQ165dtX//frm4uEi6Mg8592fpShDOfWfs4uKS5+K99PR0SVK5cuUK1UZRlClTRt7e3kVe/1qFfQcE3G5eXl4Oe5ZMYuzAcTny2GHcwJEV19hJSEgodF2HDswWi8UWlnPlTq9ITEy0TaNISkpSrVq1bHWSkpLk6+srSfL09FRSUpJdG7nPq1WrpqysrOu2UdS+lytXrsjrA3cKPrYFioaxAxRNcY2dG3ljWOIX/Zl59dVX1bdvX7tl+/fvlyR5e3vL19dXbm5uio2NtZUnJyfr4MGDCgoKkiQFBwdrz549ys7OttXZuXOnvLy8VKVKlUK1AQAAgLuXQwfmjh07avv27ZozZ45OnDihb775RiNGjFDHjh1Vp04dOTs7KyIiQlOnTtWWLVsUHx+vIUOGyNPTU23btpUkdenSRSkpKRo5cqQSEhK0du1aLVmyRP3795ekQrUBAACAu5dDT8l45JFHNH36dM2dO1dz585V+fLl1alTJw0ePNhWZ9CgQcrKytKoUaOUlpam4OBgRUdH2yZxV6lSRQsWLND48eMVHh4uDw8PDRs2TOHh4YVuAwAAAHcvi+GoVxzcwXKnjTRo0KDY2x4xZ7eOnU4p9naBG3V/dTdNePHOmbZ0/MMxSk/iK+9R8spWra3az40r6W4UyvTd7+hkysmS7gYgSarhVkP/CHq12Nq7kbzm0FMyAAAAgJJGYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADDhUIF59uzZ6tGjh92yr776Sl26dFFgYKDCwsI0adIkpaWl2cpPnjwpHx+fPI/Vq1fb6sTFxSkiIkINGzZUq1atFB0dbbeNnJwczZgxQy1atFBAQID69Omj48eP39qdBQAAwB2hdEl3INfixYs1Y8YMBQcH25bt3r1bL7/8sgYPHqz27dvr+PHjGj16tC5cuKCoqChJ0qFDh1S2bFlt3rxZFovFtm758uUlSefPn1fv3r3Vpk0bjRs3Tvv27dO4ceNUsWJFdenSRdKVoB4TE6OoqChVq1ZNU6ZMUb9+/bRx40Y5OzvfxqMAAAAAR1PiZ5jPnDmj559/XtOnT5eXl5ddWUxMjEJCQvTCCy+odu3aatmypYYMGaINGzYoIyNDknT48GF5eXmpatWq8vDwsD1cXFwkSatWrZKzs7PGjh2rOnXqqEuXLurVq5fmz58vScrIyNDChQsVGRmp0NBQ+fr6atq0aTpz5ow2bdp0ew8GAAAAHE6JB+YDBw6oQoUK2rBhgwICAuzK+vTpo2HDhuVZJysrSykpKZKunGH29vYusP3du3crODhYpUv/72R6SEiIjh49qnPnzik+Pl6XLl1SSEiIrdzd3V1+fn7atWvXze4eAAAA7nAlPiUjLCxMYWFh+Zb5+fnZPc/IyNCiRYtUr149Va5cWdKVM8weHh7q1q2bjh07ptq1a2vgwIFq0aKFJCkxMVFWq9WunapVq0qSTp06pcTERElS9erV89Q5ffr0ze8gAAAA7mglHpgLKysrS8OGDVNCQoKWL18u6UqAPnbsmFxdXTVs2DCVK1dOGzZsUL9+/bRo0SI1bdpUaWlpeeYhly1bVpKUnp6u1NRUScq3zsWLF4vcX8MwdPny5SKvfy2LxSJXV9diaw8oLqmpqTIMo6S7USDGDhyVI48dxg0cWXGNHcMw7K5/M3NHBOaUlBQNHjxYsbGxmjFjhm3qhrOzs3bt2qXSpUvbAm/9+vV15MgRRUdHq2nTpnJxcbHNd86Vnp4uSSpXrpxtrnNGRobt59w6N/NikZmZqbi4uCKvfy1XV9c8Z9wBR3D06FHbG09HxNiBo3LkscO4gSMrzrFT2Js7OHxgTkpKUr9+/fTbb79p/vz5dnONpSuh91pWq1Xbtm2TJHl6eiopKSlPm5JUrVo1ZWVl2ZbVqlXLro6vr2+R+12mTBnTudU3qrDvgIDbzcvLy2HPkkmMHTguRx47jBs4suIaOwkJCYWu69CB+eLFi+rZs6dSUlK0YsUK+fj42JXHx8fr2Wef1fz58xUUFGRb/vPPP9vCanBwsGJiYpSdna1SpUpJknbu3CkvLy9VqVJF5cuXl5ubm2JjY22BOTk5WQcPHlRERESR+26xWPIN88BfDR/bAkXD2AGKprjGzo28MSzxu2SYiYqK0q+//qopU6aocuXKOnv2rO2RnZ0tq9WqBx98UOPGjdPu3bt15MgRRUVFad++fRowYIAkqUuXLkpJSdHIkSOVkJCgtWvXasmSJerfv7+kK6fiIyIiNHXqVG3ZskXx8fEaMmSIPD091bZt25LcfQAAADgAhz3DnJOTo88++0yZmZnq2bNnnvItW7aoZs2amjt3rqZOnarBgwcrOTlZfn5+WrRoke1sdJUqVbRgwQKNHz9e4eHh8vDw0LBhwxQeHm5ra9CgQcrKytKoUaOUlpam4OBgRUdH86UlAAAAcKzAPHHiRNvPTk5O+umnn667TuXKlTVhwgTTOv7+/lq5cmWB5aVKldLQoUM1dOjQwncWAAAAdwWHnpIBAAAAlDQCMwAAAGCCwAwAAACYIDADAAAAJgjMAAAAgAkCMwAAAGCCwAwAAACYIDADAAAAJgjMAAAAgAkCMwAAAGCCwAwAAACYIDADAAAAJgjMAAAAgAkCMwAAAGCCwAwAAACYIDADAAAAJgjMAAAAgAkCMwAAAGCCwAwAAACYIDADAAAAJgjMAAAAgAkCMwAAAGCCwAwAAACYIDADAAAAJgjMAAAAgAkCMwAAAGCCwAwAAACYIDADAAAAJgjMAAAAgIkiBeZdu3bp0qVL+ZYlJyfr008/valOAQAAAI6iSIH5ueee05EjR/ItO3jwoIYPH35TnQIAAAAcRenCVnz99dd1+vRpSZJhGBo7dqzc3Nzy1Dt27Jjuvffe4ushAAAAUIIKfYa5ffv2MgxDhmHYluU+z304OTmpYcOGioqKuiWdBQAAAG63Qp9hDgsLU1hYmCSpR48eGjt2rOrUqXPLOgYAAAA4gkIH5qstXbq0uPsBAAAAOKQiBebU1FTNnTtX//nPf5SamqqcnBy7covFos2bNxdLBwEAAICSVKTAPH78eK1Zs0aNGzdW3bp15eTE7ZwBAADw11SkwPzll19qyJAheuGFF4q7PwAAAIBDKdKp4aysLPn7+xd3XwAAAACHU6TA/PDDD2vr1q3F3RcAAADA4RRpSsZjjz2mMWPG6I8//lBAQIBcXV3z1Hn88cdvtm8AAABAiStSYB48eLAkaf369Vq/fn2ecovFQmAGAADAX0KRAvOWLVuKux8AAACAQypSYK5Ro0Zx9wMAAABwSEUKzLNmzbpunZdffrkoTQMAAAAOpdgDs5ubm6pWrUpgBgAAwF9CkW4rFx8fn+fxww8/aP78+apQoYLefPPNInVm9uzZ6tGjh92yuLg4RUREqGHDhmrVqpWio6PtynNycjRjxgy1aNFCAQEB6tOnj44fP17sbQAAAODuVGzfaV2uXDm1aNFCL730kiZPnnzD6y9evFgzZsywW3b+/Hn17t1b999/v9asWaPIyEhNnz5da9assdWZPXu2YmJi9Pbbb2vlypWyWCzq16+fMjIyiq0NAAAA3L2KLTDnql69uo4cOVLo+mfOnNHzzz+v6dOny8vLy65s1apVcnZ21tixY1WnTh116dJFvXr10vz58yVJGRkZWrhwoSIjIxUaGipfX19NmzZNZ86c0aZNm4qtDQAAANy9ii0wG4ahU6dOaf78+Td0F40DBw6oQoUK2rBhgwICAuzKdu/ereDgYJUu/b+p1iEhITp69KjOnTun+Ph4Xbp0SSEhIbZyd3d3+fn5adeuXcXWBgAAAO5eRbroz9fXVxaLJd8ywzBuaEpGWFiYwsLC8i1LTEyU1Wq1W1a1alVJ0qlTp5SYmCjpylnta+ucPn262NooCsMwdPny5SKvfy2LxZLvNyoCJS01NVWGYZR0NwrE2IGjcuSxw7iBIyuusWMYRoF59lpFCswvvfRSvhtwc3NTq1atdP/99xel2TzS0tLk7Oxst6xs2bKSpPT0dKWmpkpSvnUuXrxYbG0URWZmpuLi4oq8/rVcXV3l5+dXbO0BxeXo0aO2ceSIGDtwVI48dhg3cGTFOXauzX8FKVJgjoyMLMpqN8zFxSXPhXfp6emSrlxk6OLiIunKPOTcn3Pr5L4zLo42iqJMmTLy9vYu8vrXKuw7IOB28/LyctizZBJjB47LkccO4waOrLjGTkJCQqHrFikwS1cC5tq1axUbG6vk5GRVqlRJQUFBCg8Pt53BvVmenp5KSkqyW5b7vFq1asrKyrItq1Wrll0dX1/fYmujKCwWi8qVK1fk9YE7BR/bAkXD2AGKprjGzo28MSzSRX/Jycl6+umnNXbsWP34449KSUnRDz/8oLFjx+rJJ5/Un3/+WZRm8wgODtaePXuUnZ1tW7Zz5055eXmpSpUq8vX1lZubm2JjY+36dvDgQQUFBRVbGwAAALh7FSkwv/POO0pMTNSyZcv01VdfaeXKlfrqq6+0bNkynTt3TtOnTy+WznXp0kUpKSkaOXKkEhIStHbtWi1ZskT9+/eXdGXeSUREhKZOnaotW7YoPj5eQ4YMkaenp9q2bVtsbQAAAODuVaQpGVu2bNHgwYPznIENCgrSoEGDNHv2bI0aNeqmO1elShUtWLBA48ePV3h4uDw8PDRs2DCFh4fb6gwaNEhZWVkaNWqU0tLSFBwcrOjoaNsk7uJoAwAAAHevIgXmS5cu6b777su37L777tOFCxeK1JmJEyfmWebv76+VK1cWuE6pUqU0dOhQDR06tMA6xdEGAAAA7k5FmpLxwAMP6D//+U++ZVu2bFHt2rVvqlMAAACAoyjSGea+ffvqlVdeUUZGhjp16qR7771Xv//+u/71r39p9erVGjt2bDF3EwAAACgZRQrMjz32mI4dO6a5c+dq9erVtuVlypTRSy+9pK5duxZbBwEAAICSVKTAfPnyZQ0cOFARERHat2+fLl68qNOnT6tr166qUKFCcfcRAAAAKDE3NIc5Li5Ojz/+uBYvXixJcnd3V8uWLdWyZUu999576tatm44cOXIr+gkAAACUiEIH5l9//VW9evXSxYsX83zls7Ozs0aMGKFLly6pW7duSkxMLPaOAgAAACWh0IF53rx5qlSpktatW6d27drZlbm6uioiIkJr1qxRuXLlNHfu3GLvKAAAAFASCh2Yd+7cqeeff14VK1YssE6VKlXUu3dv7dy5szj6BgAAAJS4Qgfms2fPFur+ylarlSkZAAAA+MsodGCuXLmykpKSrlvvjz/+MD0LDQAAANxJCh2Yg4ODtXbt2uvWW79+verWrXtTnQIAAAAcRaEDc48ePRQbG6uJEycqPT09T3lGRoYmTZqkb7/9Vt27dy/WTgIAAAAlpdBfXNKgQQMNHz5cEyZM0CeffKKmTZuqZs2ays7O1qlTpxQbG6vz58/rH//4h1q0aHEr+wwAAADcNjf0TX/du3eXr6+voqOjtWXLFtuZ5nvuuUcPP/yw+vTpo4CAgFvSUQAAAKAk3PBXYz/00EN66KGHJEnnz5+Xk5MTX4cNAACAv6wbDsxXq1SpUnH1AwAAAHBIhb7oDwAAALgbEZgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMlC7pDlxPbGysnnvuuXzLatasqS1btmj48OFau3atXVm1atW0detWSVJOTo5mzZql1atXKzk5WQ899JDGjBmj2rVr2+rHxcVp/Pjx+vnnn1WxYkX16NFDffv2vXU7BgAAgDuCwwfmwMBAbdu2zW7Z4cOH9cILL2jAgAGSpEOHDmnAgAGKiIiw1SlVqpTt59mzZysmJkZRUVGqVq2apkyZon79+mnjxo1ydnbW+fPn1bt3b7Vp00bjxo3Tvn37NG7cOFWsWFFdunS5PTsKAAAAh+TwgdnZ2VkeHh6255mZmYqKilK7du301FNPKTs7WwkJCRo4cKBdvVwZGRlauHChhg4dqtDQUEnStGnT1KJFC23atEkdOnTQqlWr5OzsrLFjx6p06dKqU6eOjh8/rvnz5xOYAQAA7nJ33Bzm5cuX6/Tp0xo+fLgk6dixY0pPT1edOnXyrR8fH69Lly4pJCTEtszd3V1+fn7atWuXJGn37t0KDg5W6dL/e/8QEhKio0eP6ty5c7dwbwAAAODoHP4M89XS09M1d+5c9ezZU1WrVpV0ZXqGxWLRkiVLtHXrVjk5OSk0NFSDBw9W+fLllZiYKEmqXr26XVtVq1bV6dOnJUmJiYmyWq15yiXp1KlTqlKlyg331TAMXb58+YbXK4jFYpGrq2uxtQcUl9TUVBmGUdLdKBBjB47KkccO4waOrLjGjmEYslgshap7RwXmTz75ROnp6erRo4dt2X//+185OTmpRo0amjt3ro4fP65Jkybp8OHDWrJkiVJTUyVdmdpxtbJly+rixYuSpLS0tHzLpSshvSgyMzMVFxdXpHXz4+rqKj8/v2JrDyguR48etY0zR8TYgaNy5LHDuIEjK86xc23+K8gdFZjXr1+vdu3aqVKlSrZlkZGR6tWrl9zd3SVJVqtVHh4e6tq1q/bv3y8XFxdJV+Yy5/4sXQnCue+eXVxclJGRYbet3KBcrly5IvW1TJky8vb2LtK6+SnsOyDgdvPy8nLYs2QSYweOy5HHDuMGjqy4xk5CQkKh694xgfmPP/7Q3r171b9/f7vlFovFFpZz5U6vSExMtE3FSEpKUq1atWx1kpKS5OvrK0ny9PRUUlKSXRu5z6tVq1ak/losliKHbeBOwse2QNEwdoCiKa6xcyNvDO+Yi/5++OEHWSwWNW7c2G75q6++mud+yfv375ckeXt7y9fXV25uboqNjbWVJycn6+DBgwoKCpIkBQcHa8+ePcrOzrbV2blzp7y8vIo0fxkAAAB/HXdMYI6Pj9d9992X511Fx44dtX37ds2ZM0cnTpzQN998oxEjRqhjx46qU6eOnJ2dFRERoalTp2rLli2Kj4/XkCFD5OnpqbZt20qSunTpopSUFI0cOVIJCQlau3atlixZkudsNgAAAO4+d8yUjN9//10VK1bMs/yRRx7R9OnTNXfuXM2dO1fly5dXp06dNHjwYFudQYMGKSsrS6NGjVJaWpqCg4MVHR1tm+hdpUoVLViwQOPHj1d4eLg8PDw0bNgwhYeH36a9AwAAgKO6YwLz2LFjCyxr37692rdvX2B5qVKlNHToUA0dOrTAOv7+/lq5cuXNdBEAAAB/QXfMlAwAAACgJBCYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATBCYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATBCYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATBCYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATBCYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATBCYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATBCYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATBCYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATBCYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATBCYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATBCYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATNwRgfnkyZPy8fHJ81i9erUkKS4uThEREWrYsKFatWql6Ohou/VzcnI0Y8YMtWjRQgEBAerTp4+OHz9uV+d6bQAAAODuVLqkO1AYhw4dUtmyZbV582ZZLBbb8vLly+v8+fPq3bu32rRpo3Hjxmnfvn0aN26cKlasqC5dukiSZs+erZiYGEVFRalatWqaMmWK+vXrp40bN8rZ2blQbQAAAODudEcE5sOHD8vLy0tVq1bNU7ZkyRI5Oztr7NixKl26tOrUqaPjx49r/vz56tKlizIyMrRw4UINHTpUoaGhkqRp06apRYsW2rRpkzp06KBVq1aZtgEAAIC71x0xJePQoUPy9vbOt2z37t0KDg5W6dL/y/4hISE6evSozp07p/j4eF26dEkhISG2cnd3d/n5+WnXrl2FagMAAAB3rzsiMB8+fFjnzp1Tt27d1KxZMz377LP69ttvJUmJiYny9PS0q597JvrUqVNKTEyUJFWvXj1PndOnTxeqDQAAANy9HH5KRkZGho4dOyZXV1cNGzZM5cqV04YNG9SvXz8tWrRIaWlpcnZ2tlunbNmykqT09HSlpqZKUr51Ll68KEnXbaMoDMPQ5cuXi7RufiwWi1xdXYutPaC4pKamyjCMku5GgRg7cFSOPHYYN3BkxTV2DMOwuzbOjMMHZmdnZ+3atUulS5e2hdr69evryJEjio6OlouLizIyMuzWyQ255cqVk4uLi6QrwTv359w6uS8G12ujKDIzMxUXF1ekdfPj6uoqPz+/YmsPKC5Hjx61vTF1RIwdOCpHHjuMGziy4hw7154wLYjDB2Yp/9BqtVq1bds2eXp6Kikpya4s93m1atWUlZVlW1arVi27Or6+vpJ03TaKokyZMgXOuy6Kwr4DAm43Ly8vhz1LJjF24LgceewwbuDIimvsJCQkFLquwwfm+Ph4Pfvss5o/f76CgoJsy3/++Wd5e3urbt26iomJUXZ2tkqVKiVJ2rlzp7y8vFSlShWVL19ebm5uio2NtQXm5ORkHTx4UBEREZKk4OBg0zaKwmKxFPnsNHAn4WNboGgYO0DRFNfYuZE3hg5/0Z/VatWDDz6ocePGaffu3Tpy5IiioqK0b98+DRgwQF26dFFKSopGjhyphIQErV27VkuWLFH//v0lXTnVHhERoalTp2rLli2Kj4/XkCFD5OnpqbZt20rSddsAAADA3cvhzzA7OTlp7ty5mjp1qgYPHqzk5GT5+flp0aJF8vHxkSQtWLBA48ePV3h4uDw8PDRs2DCFh4fb2hg0aJCysrI0atQopaWlKTg4WNHR0bZ5K1WqVLluGwAAALg7OXxglqTKlStrwoQJBZb7+/tr5cqVBZaXKlVKQ4cO1dChQ4vcBgAAAO5ODj8lAwAAAChJBGYAAADABIEZAAAAMEFgBgAAAEwQmAEAAAATBGYAAADABIEZAAAAMEFgBgAAAEwQmAEAAAATBGYAAADABIEZAAAAMEFgBgAAAEwQmAEAAAATBGYAAADABIEZAAAAMEFgBgAAAEwQmAEAAAATBGYAAADABIEZAAAAMEFgBgAAAEwQmAEAAAATBGYAAADABIEZAAAAMEFgBgAAAEwQmAEAAAATBGYAAADABIEZAAAAMEFgBgAAAEwQmAEAAAATBGYAAADABIEZAAAAMEFgBgAAAEwQmAEAAAATBGYAAADABIEZAAAAMEFgBgAAAEwQmAEAAAATBGYAAADABIEZAAAAMEFgBgAAAEwQmAEAAAATBGYAAADABIEZAAAAMEFgBgAAAEwQmAEAAAATBGYAAADAhMMH5gsXLmj06NFq2bKlGjVqpGeffVa7d++2lQ8fPlw+Pj52j5YtW9rKc3JyNGPGDLVo0UIBAQHq06ePjh8/breNuLg4RUREqGHDhmrVqpWio6Nv2/4BAADAsTl8YH7llVf0448/6t1339XHH3+sevXqqW/fvjpy5Igk6dChQxowYIC2bdtme6xfv962/uzZsxUTE6O3335bK1eulMViUb9+/ZSRkSFJOn/+vHr37q37779fa9asUWRkpKZPn641a9aUxO4CAADAwTh0YD5+/Li2b9+uMWPGKCgoSA888IBGjhypatWqaePGjcrOzlZCQoIaNGggDw8P26Ny5cqSpIyMDC1cuFCRkZEKDQ2Vr6+vpk2bpjNnzmjTpk2SpFWrVsnZ2Vljx45VnTp11KVLF/Xq1Uvz588vyV0HAACAg3DowFypUiXNmzdP9evXty2zWCwyDEMXL17UsWPHlJ6erjp16uS7fnx8vC5duqSQkBDbMnd3d/n5+WnXrl2SpN27dys4OFilS5e21QkJCdHRo0d17ty5W7RnAAAAuFOUvn6VkuPu7q7Q0FC7ZZ9//rlOnDihhx9+WIcPH5bFYtGSJUu0detWOTk5KTQ0VIMHD1b58uWVmJgoSapevbpdG1WrVtXp06clSYmJibJarXnKJenUqVOqUqVKkfpuGIYuX75cpHXzY7FY5OrqWmztAcUlNTVVhmGUdDcKxNiBo3LkscO4gSMrrrFjGIYsFkuh6jp0YL7Wnj17NGLECLVu3VphYWGaMWOGnJycVKNGDc2dO1fHjx/XpEmTdPjwYS1ZskSpqamSJGdnZ7t2ypYtq4sXL0qS0tLS8i2XpPT09CL3NTMzU3FxcUVe/1qurq7y8/MrtvaA4nL06FHbWHNEjB04KkceO4wbOLLiHDvXZsCC3DGBefPmzXrttdcUEBCgd999V5IUGRmpXr16yd3dXZJktVrl4eGhrl27av/+/XJxcZF0ZS5z7s/SlSCc+87ZxcXFdgHg1eWSVK5cuSL3t0yZMvL29i7y+tcq7Dsg4Hbz8vJy2LNkEmMHjsuRxw7jBo6suMZOQkJCoeveEYF52bJlGj9+vNq2baupU6fa3g1YLBZbWM6VO70iMTHRNhUjKSlJtWrVstVJSkqSr6+vJMnT01NJSUl2beQ+r1atWpH7bLFYbipwA3cKPrYFioaxAxRNcY2dG3lj6NAX/UnSihUr9NZbb6l79+5677337E6dv/rqq+rbt69d/f3790uSvL295evrKzc3N8XGxtrKk5OTdfDgQQUFBUmSgoODtWfPHmVnZ9vq7Ny5U15eXkWevwwAAIC/DocOzEePHtWECRPUtm1b9e/fX+fOndPZs2d19uxZ/fnnn+rYsaO2b9+uOXPm6MSJE/rmm280YsQIdezYUXXq1JGzs7MiIiI0depUbdmyRfHx8RoyZIg8PT3Vtm1bSVKXLl2UkpKikSNHKiEhQWvXrtWSJUvUv3//Et57AAAAOAKHnpLxxRdfKDMzU5s2bbLdNzlXeHi4Jk6cqOnTp2vu3LmaO3euypcvr06dOmnw4MG2eoMGDVJWVpZGjRqltLQ0BQcHKzo62namukqVKlqwYIHGjx+v8PBweXh4aNiwYQoPD7+duwoAAAAH5dCBecCAARowYIBpnfbt26t9+/YFlpcqVUpDhw7V0KFDC6zj7++vlStXFrmfAAAA+Oty6CkZAAAAQEkjMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMP9/OTk5mjFjhlq0aKGAgAD16dNHx48fL+luAQAAoIQRmP+/2bNnKyYmRm+//bZWrlwpi8Wifv36KSMjo6S7BgAAgBJEYJaUkZGhhQsXKjIyUqGhofL19dW0adN05swZbdq0qaS7BwAAgBJEYJYUHx+vS5cuKSQkxLbM3d1dfn5+2rVrVwn2DAAAACWtdEl3wBEkJiZKkqpXr263vGrVqjp9+vQNt5eZmSnDMPTTTz8VS/9yWSwWdQh0Ura/W7G2CxRFqVJO2r9/vwzDKOmuXJfFYlG2T3sZD2aVdFcAXXYqreQ7YOxYLBY1dmqmHLfsku4KIElycipVrP93MjMzZbFYClWXwCwpNTVVkuTs7Gy3vGzZsrp48eINt5d78Av7S7gR7veUKfY2gZtxK/7Ob4VS5cqXdBcAO3fC2HErwwkaOJ7iGjsWi4XAfCNcXFwkXZnLnPuzJKWnp8vV1fWG2wsMDCy2vgEAAKBkMYdZ/5uKkZSUZLc8KSlJnp6eJdElAAAAOAgCsyRfX1+5ubkpNjbWtiw5OVkHDx5UUFBQCfYMAAAAJY0pGboydzkiIkJTp05V5cqVVaNGDU2ZMkWenp5q27ZtSXcPAAAAJYjA/P8NGjRIWVlZGjVqlNLS0hQcHKzo6Og8FwICAADg7mIxHP2+NgAAAEAJYg4zAAAAYILADAAAAJggMAMAAAAmCMwAAACACQIzAAAAYILADAAAAJggMAMAAAAmCMy4a+Tk5GjGjBlq0aKFAgIC1KdPHx0/frykuwXcUWbPnq0ePXqUdDcAh3fhwgWNHj1aLVu2VKNGjfTss89q9+7dJd0tFBGBGXeN2bNnKyYmRm+//bZWrlwpi8Wifv36KSMjo6S7BtwRFi9erBkzZpR0N4A7wiuvvKIff/xR7777rj7++GPVq1dPffv21ZEjR0q6aygCAjPuChkZGVq4cKEiIyMVGhoqX19fTZs2TWfOnNGmTZtKunuAQztz5oyef/55TZ8+XV5eXiXdHcDhHT9+XNu3b9eYMWMUFBSkBx54QCNHjlS1atW0cePGku4eioDAjLtCfHy8Ll26pJCQENsyd3d3+fn5adeuXSXYM8DxHThwQBUqVNCGDRsUEBBQ0t0BHF6lSpU0b9481a9f37bMYrHIMAxdvHixBHuGoipd0h0AbofExERJUvXq1e2WV61aVadPny6JLgF3jLCwMIWFhZV0N4A7hru7u0JDQ+2Wff755zpx4oQefvjhEuoVbgZnmHFXSE1NlSQ5OzvbLS9btqzS09NLoksAgLvEnj17NGLECLVu3Zo3n3coAjPuCi4uLpKU5wK/9PR0ubq6lkSXAAB3gc2bN6tv377y9/fXu+++W9LdQRERmHFXyJ2KkZSUZLc8KSlJnp6eJdElAMBf3LJlyxQZGamWLVtq/vz5tpM3uPMQmHFX8PX1lZubm2JjY23LkpOTdfDgQQUFBZVgzwAAf0UrVqzQW2+9pe7du+u9997LMyUQdxYu+sNdwdnZWREREZo6daoqV66sGjVqaMqUKfL09FTbtm1LunsAgL+Qo0ePasKECWrbtq369++vc+fO2cpcXFxUvnz5EuwdioLAjLvGoEGDlJWVpVGjRiktLU3BwcGKjo7mXT8AoFh98cUXyszM1KZNm/Lc6z88PFwTJ04soZ6hqCyGYRgl3QkAAADAUTGHGQAAADBBYAYAAABMEJgBAAAAEwRmAAAAwASBGQAAADBBYAYAAABMEJgBB1LUuzxyd8hbg+MK/LUwplFUBGbc1YYNGyYfHx/NmzevpLui1atXa9KkSTe83pw5cxQdHW17PnPmTPn4+BRn167rp59+Uvv27ZWRkWFbtmjRIrVp00YNGjTQ3//+d23evPmWbb9Hjx7q0aNHgeVhYWF64403bqjNhIQEPfvsszfbNZuvvvpKPXv2VFBQkBo0aKC2bdvq7bff1u+//15s27gVfHx8NHPmzGJv9+WXX77h30lRXLp0SbNnz1bnzp3VsGFDNW7cWM8884xWrlyprKysPPWnTp2qJk2aqGHDhlq/fr1iY2PVvn171a9fX3379r3l/b3a9f6ub6WUlBRNnjxZbdu2VcOGDdWxY0ctX75cOTk5t2R7YWFhatSokU6dOpVveVH+Dq89fte+xq5du1Y+Pj767bffitbp6/jjjz8UGhqqX3/99Za0j9uLwIy7VkpKir788ktZrVatWrWqxM88zJkzRxcuXLjh9d577z2lpqbanj/11FNauXJlMfbMXHp6ul5//XW9+uqrtm9NXLBggaZMmaLw8HDNmjVLtWvX1qBBg7Rr167b1q+b9fnnn2vv3r3F0ta6dev04osvqnbt2poyZYrmz5+vnj176ssvv1TXrl2L9Hu/U2VnZ+utt97K8+1nt8Lp06fVpUsXLVmyRO3atdOcOXM0efJk+fv7a/z48erdu7f+/PNPW/3Dhw9r/vz5ateunRYsWKCWLVtq0qRJysnJ0bx58zRs2LBb3uerjRkzRmPGjLmt28z16quvas2aNerVq5fmzJmj1q1ba/z48ZozZ84t2+alS5c0atSoYmvv2uNX1NfYoqpcubJ69eqlESNGlPj/F9w8vhobd61PP/1U2dnZGjVqlJ577jlt27ZNLVq0KOlu3TRPT095enretu2tWLFCFotF7dq1kySlpaXpgw8+UK9evfTSSy9Jklq2bKlnnnlG77//vhYvXnzb+uYo3n//fXXs2FH//Oc/bctCQkIUFBSkv//97/r444/1/PPPl2APb4/4+Hi99dZb+vnnn+Xi4nJLt2UYhgYNGqTU1FStW7dO//d//2cra9WqlR599FE999xz+uc//6kpU6ZIki1MdejQQUFBQbZlwcHBatas2S3tb368vb1v+zYl6cCBA/r666/13nvv6dFHH5UkNW3aVMnJyVqwYIEGDhwoi8VS7Nt1d3fX9u3btWrVKj399NM33V5JHb+rdevWTXPnztXmzZvVtm3bku4ObgJnmHHXWrNmjZo0aaImTZrIy8tLMTExduU9evTQyJEjNW/ePLVq1UoNGjTQM888ox9//NFWZ+bMmWrbtq2+/vprderUSfXr11f79u21bt06u7aSkpI0fPhwhYaGyt/fX08++aS2bNliKw8LC9PJkye1bt06u48Id+3apb59+yo4OFj169dXWFiYZs6caftYNHfqxaxZs2w/5zcl47PPPtMTTzyhwMBANW/eXKNHj9bFixdveD+ulZGRoUWLFqlTp062ZT/++KOSk5NtAVqSLBaL2rZtq++//15paWn5tpXb74Iea9euNe3LjUhLS9M777yjdu3aqX79+mrUqJF69+6tuLg4W19mzZolyf6j4NwzjW3btrUdo6VLl153e7///nu+Z5h8fX01fPhw1a9f37bMx8dHy5Yt0+uvv67AwEA1a9ZMb7/9dp7jtnnzZj3xxBNq0KCBmjdvrrfffluXL1+2q3P48GH1799fjRo1UqNGjfTSSy/l+Xj43LlzGjFihJo1a6bAwEB1795de/bssauTkpKikSNHqnHjxgoMDNSgQYN07ty56+73tV5//XXl5ORo5cqVqlKlSqHWCQsLM/27KMg333yjn376Sa+99ppdWM4VGBionj17asOGDTpx4oRmzpxp+/i+Z8+etu2ePHlS69evl4+Pj2JjYyVd/7jGxsbKx8dHO3fuVJ8+fRQQEKBmzZpp0qRJdtNAduzYoa5duyowMFDBwcEaOHCgfvnlF1v51VMK+vTpo8cffzzPfgwePFgdOnSwPd+9e7ciIiIUEBCgxo0b6/XXX9cff/xRqGN9ta5du6pp06Z2y+6//35dvny5wN/9zY7hsLAwNW7cWJMmTdLp06dN6xZmLF59/Ap6jZWuvGY988wzatCggVq1amU3xU268ina5MmTFRoaqvr166tTp0767LPP8vR9woQJ6tmzpxo1aqTRo0dLksqWLat27drpgw8+MN0f3AEM4C6UkJBgWK1WY+PGjYZhGMYHH3xg1K1b10hMTLTViYiIMB566CHj6aefNjZt2mR8+eWXRuvWrY2WLVsaWVlZhmEYxowZM4yAgADjkUceMVatWmVs377d6NOnj2G1Wo2EhATDMAzj7NmzRosWLYywsDBj3bp1xtdff20MGjTI8PHxMT755BPDMAzjwIEDRvPmzY1+/foZe/fuNdLT0424uDjDz8/PeOWVV4xvv/3W2Lp1q/Hqq68aVqvV2LBhg2EYhrF3717DarUaI0aMMPbu3Wvrk9Vqte3H+++/b1itVmPs2LHG1q1bjeXLlxuNGzc2OnXqZKSmphZ6P/KzdetWw2q1Gr/88ott2fLlyw2r1WqcP3/eru6XX35pWK1W49ChQ/m2dfr0aWPv3r0FPs6dO1dgPyIiIozu3bsbmZmZ+T4eeeQR4/XXX7fVj4yMNEJCQozVq1cbsbGxxsqVK41mzZoZ7du3N3JycozTp08bI0aMMKxWq7F3717j9OnThmEYxptvvmnUq1fPmDFjhvHtt98a7777ruHr62vMmjWrwL4ZhmH84x//MKxWqzFw4EDjX//6l93f2bWsVqsRFBRk9O3b1/j666+N6Ohoo0GDBsbLL79sq7NhwwbDarUar776qvHNN98YK1asMIKDg42ePXsaOTk5hmEYxi+//GIEBgYaXbp0Mb744gvjs88+Mzp16mQ0b97c+P333w3DMIxLly4Zbdq0MUJDQ42PP/7Y2LZtm9GvXz+jYcOGtt+71Wo1fH19jaFDhxo7duwwlixZYtSrV8+IjIw03ef8xMXF2X6+9ndSkAMHDpj+XRTkn//8p+Hr62v8+eefBdY5ePCgYbVajUWLFhmnT582li1bZlitVmPZsmXGvn37jL1799qNyz///LNQx/W7774zrFar0axZM2PWrFnGjh07jAkTJhhWq9X46KOPDMMwjBMnThj+/v7GuHHjjJ07dxr//ve/jfbt2xutW7c2srOzDcO48ncdERFhGIZhrF+/3rBarcaRI0ds/U9JSTH8/f2NDz74wDAMw/j++++NevXqGX379jW++uorY926dUarVq2MDh062Mb6zejevbvRtGlTW/+udTNjOPfv4cSJE0bDhg2NPn362JVbrVZjxowZtueFGYtXH7/8XmPXrFljG29Lly41tm/fbkRGRhpWq9X46quvDMMwjJycHKNv375GYGCgsWjRImPr1q3Gm2++aVitVmPdunV2/ffz8zPGjx9vbNu2zdi9e7etbPv27XleJ3HnITDjrjRx4kQjKCjISEtLMwzDMM6cOWPUrVvXmDlzpq1ORESEERAQYPcPd926dYbVajX2799vGMb/wumOHTtsdU6ePGlYrVYjOjraMAzDmDx5slGvXj3jxIkTdn3o2bOn0bx5c9s/n2sDxLp164znn3/e7p9Tdna28dBDDxlvvvmmbdm1/0iuDswXLlww6tevb4wcOdJu27t27TKsVquxfPnyQu9HfiZPnmwEBQXZLZs7d65htVqNzMxMu+W5/zT27NlTYHtFFRERYVitVtNH7rFNT083+vTpY3z66ad2bSxcuNCwWq3GmTNnDMPI+8bjl19+MXx8fGzhJNe0adOMBg0aGH/88UeB/UtOTjYiIyMNHx8fW3/atGljTJgwwRbGc1mtVqNdu3Z2x2/RokWG1Wo1Dh8+bOTk5BgtW7Y0+vbta7fejh07DKvVavznP/8xDMMwXnnlFaNp06Z2f7/nz583HnroIWPixImGYRjGsmXLDB8fH7sgm5aWZvztb3+zBTur1Wo89dRTdtt69dVXjeDg4AL3tzAKG5iL6oUXXjBCQkJM66SkpBhWq9V46623DMP4X9D97rvvCuxnYY5rbjvTpk2z215YWJjRv39/wzAMY+PGjYbVarV78/Tjjz8a7777rq3tqwPfpUuXjIYNG9q9Rq1bt87w8fExTp06ZRiGYXTt2tXo2LGj7Q29YVz5u61bt66xbNmy6xwxc7njY/HixTfVTkGuPs4ffvihYbVajVWrVtnKr36dK+xYvPr4XbsNwzBsgXnFihW2ZZcuXTLq1atnTJgwwTAMw9i2bZthtVrzvF689tprRvPmzW3j9JFHHjFatWqV75uJ5ORku9db3JmYkoG7TlZWljZs2KA2bdooPT1dycnJcnFxUZMmTbR69WplZ2fb6np7e8vNzc32vFq1apJkd5GdJDVs2ND2c+784dyPx7///nsFBgbqvvvus1unc+fOOnv2rN1HsFd7/PHHNX/+fGVmZuq///2vNm/erJkzZyo7O1uZmZmF2td9+/YpIyPDbsqEJAUFBalGjRq2j5gLsx/5+fXXX1WjRg27ZQVdRW/8/ykJTk75v+zk5OQoKyurwIdxnYtm6tWrp48//jjfh4eHh62es7OzoqOj9dhjjykpKUm7du3SypUr9Z///EeSCjy23333nQzDUFhYmF2/wsLClJ6enmcaw9XKly+vGTNmaPPmzRo9erTat2+v5ORkLV68WI8++qh++OEHu/odOnRQ6dL/u8Skffv2kq583P7LL78oMTExTz+Cg4Pl5uam7du32/rbpEkTubi42Oq4ubkpKChIO3bssLVXs2ZN+fr62rZVtmxZff7553rmmWdsyx566CG7/t13331KTk4u+JdRjLKzs03/LgpiGIbdMczP9crzU5jjmiswMNDuuaenp208BQQEqGzZsnryyScVFRWlHTt2yNfXV0OGDLF7zclVrlw5tW3b1m4qwKeffqrGjRurevXqSk1N1Y8//qjQ0FAZhmHr23333ac6derY/i6KYsmSJZo0aZI6duyo5557rsB6NzuGc0VERCg4OFgTJ05UYmJinvKbGYv5yZ2vLl05zvfee6/t73vnzp2yWCwKDQ3Ns62zZ8/qv//9r23dOnXq5Pv6Vr58ebm7u9+yu3Hg9uCiP9x1vv76a/3+++9au3ZtvnPq/vOf/6hNmzaSJFdXV7uy3BfDa0Ph1fVy6+T+c7h48aJq1qyZZzv33nuvJBUYPNLS0vTWW2/pk08+UVZWlmrWrKnAwECVLl260P94cucp527r2u1ffYeA6+1HflJSUvIcI3d3d0lXrnivUKGCbXluUChfvny+bb3//vu2ecP5iYqK0hNPPFFg+T333KMGDRrkW5Z7945c3377rSZMmKBffvlF99xzj3x8fHTPPfdIKnh/r74gLD9nzpwpsG+5atasqe7du6t79+7KycnR5s2bNXz4cL399tt2f4tVq1a1Wy93vm9ycrKtH+PGjdO4cePybCMpKcnW388++yzPXEvpytX7uXUKM5e4XLlyds+dnJxu21X/bdu21cmTJwssP3ToUL7La9Sooe3btystLa3ACwxz5x3nN8e5IIU5rrmu3e7Vx61mzZpatmyZ5s2bp1WrVmnx4sVyd3dXt27d9I9//CPf4PX444/rk08+UXx8vKpWraodO3bYLiRNTk5WTk6O5s+fr/nz5+dZt2zZsoXex1w5OTmaPHmy7TqFiRMnml7sd7NjOJfFYtGECRPUuXNnjRo1SgsWLLArL46xeLX8Xudzf08XLlyQYRhq1KhRvusmJSWpbt26kvJ/nb16GykpKTfULzgWAjPuOh9//LFq1KihqKioPGWDBg1STEyMLTAXhwoVKuR7r92zZ89KkipVqpTveuPHj9cXX3yh9957T82aNbOFlmsvxLnetqUrF53VqVMnz/avPet9oypVqmQLaLm8vLwkScePH5e/v79t+fHjx+Xs7FzgNp9++mm1atWqwG3l96ajKE6cOKGXXnpJrVu31gcffKBatWpJkpYvX65vv/22wPVy3wgsWbLEFq6vVlDo+uKLLzRmzBh99NFHtmMjXfmn3K5dO+3atUurVq2yW+faW1/l/v1UrlzZ1o9hw4apcePGebaX+zsvX768mjVrpt69e+epk3tmtXz58vme9dq7d6/c3Nz04IMP5rtPt9OcOXPs7u9dWGFhYVqxYoU2b96sjh075lvn3//+t61uYRXmuBaWv7+/Zs2apYyMDO3Zs0crV67U3Llz5ePjo8ceeyxP/ZCQEFWrVk2ff/65qlWrptKlS9s+fbjnnntksVjUq1evfIPktaHwejIyMvTKK69o06ZN6tmzp4YPH37dO2MU5xiuVauWhgwZogkTJujjjz+2KyvqWCyK8uXLq1y5cvrwww/zLa9du3ah2klOTi7wtR53BgIz7iq///67vv32W/Xp00dNmjTJU/7YY48pJiamWG80HxwcrA8//FC//vqrXVjcsGGDPDw8bC+4155R2rNnj5o0aWIX3n/++Wf98ccfdme4C5riIF352NfZ2Vn/+te/7PZ39+7dOnXq1E3fyuz//u//9M0338gwDNs/08DAQJUrV05ffPGFLTAbhqFNmzapcePGec725qpWrZptysut9PPPPys9PV39+/e3hWVJtrBc0NSR4OBgSdL58+cVEhJit97ixYs1YsSIfM/WPvjgg7pw4YKWLFmisWPH5ik/duyYrFar3bKvvvpKAwYMsD3/4osvZLFYFBISov/7v/9TlSpV9Ntvv9l9kcbZs2c1dOhQPfPMM6pVq5YaN26shIQE1a1b1xbkDMPQa6+9ptq1a6tu3boKCgrSl19+qUOHDtnuOJGRkaHIyEg9+uijGjly5PUP6C1W1C/had68uR566CFNmjRJgYGBeaYO7d+/XwsWLNBjjz2m+++/v9DtFua4FsbixYv14Ycf6t///recnZ3VtGlT1a9fX59//nmBd4hwcnJSx44dtWXLFlWuXFmtW7e2Td9wc3OTn5+ffvnlF7tPWtLS0vSPf/xDLVu2vKHbrL3xxhu2T0B69epVqHWKeww/99xz+vLLLzVx4kS75UUdi2avlQVp3LixFi5cKMMw7E4ArF27Vl9++aUmTJhw3TYuXLig1NTUYg3yuP0IzLirrFu3TllZWQV+lBceHq4VK1bkOeN3M3r37q0NGzaod+/eevnll1WpUiWtX79e3333nSZMmGB7EXd3d9fBgwf1/fffy9/fX/7+/vr888/10UcfqU6dOoqPj9ecOXNksVjs5lC7u7tr79692rVrl91cPEmqWLGiXnjhBc2aNUtlypRR69at9dtvv2n69Ony9vYu1MejZpo3b6558+bpv//9ry30ubq6qk+fPnr//fdVpkwZBQYGas2aNTpw4ICWLFlyU9srDvXq1VPp0qU1ZcoU9enTRxkZGVq7dq2+/vprSf+bOpJ7Fmvjxo0KCAiQ1WpV586d9eabb+rkyZOqX7++jh49qmnTpqlmzZoFhq4HHnhAL7zwgj744AOdOnVKnTt3lqenp86dO6dPPvlEO3fu1KJFi+zWyb0d2t///ncdOnRIM2bM0NNPP217wzVkyBCNHj1apUqV0iOPPKLk5GTNnj1bZ86cUb169SRJAwcO1DPPPKP+/fvr2WefVdmyZbVy5Upt3rxZM2bMkCQ98cQTWrp0qV588UX94x//UOXKlbV8+XKlpaXd0DfM/fHHHzpx4kSeOf8lycnJSe+8845eeOEFPfHEE+rZs6cCAwOVk5OjHTt2aPny5fLz88t3WouZwhzXwggJCdHUqVP10ksvKSIiQqVKlVJMTIycnZ31yCOPFLje448/rujoaJUqVSrPl4i88soreuGFF/Tqq6+qc+fOys7O1sKFC/Xjjz/qxRdftNXbt2+fKleubPeG8WqbN2/Wp59+qrCwMDVs2FD79u2zK/fz8yvwjW9xunpqxtWKOhavfY0tjNDQUNst/wYOHKg6derop59+0syZM/Xwww/nmYaTn9w51Q8//HChtgnHRGDGXWXdunV68MEH7S5yupq/v78eeOABrVmzRrVq1VKZMmVuepseHh766KOP9M4772j8+PHKzMyUr6+vZs+erdatW9vq9enTRxMmTFDfvn21aNEivfHGG8rMzNR7772njIwM1axZUy+++KISEhL01VdfKTs7W6VKldKAAQM0e/Zs9evXL995lZGRkbr33nu1bNkyrV69WhUrVtTf/vY3DR48+IY/pr1WUFCQqlSpom+++cbuLOnLL7+sUqVKadWqVVq4cKG8vb01e/bsPBePlYTatWvrnXfe0axZs/Tiiy+qQoUKatiwoZYuXaoePXpo9+7d8vHxUbt27fTJJ5/ojTfe0JNPPqmxY8cqKipKH3zwgWJiYpSYmKgqVaroscce0+DBg1WqVKkCt/nKK6+obt26Wr16td5++22lpKTI3d1dQUFB+vjjj/P8Pfbs2VNnzpyxvcEaMGCA+vfvbyt/6qmndM8992jBggVauXKlypUrp0aNGmnq1Km2UO3r66vly5dr2rRpGjZsmAzDkNVq1fvvv2/7u3Nzc9OyZcs0efJkjR8/XllZWQoICNDSpUsLDFP5+frrrzV8+HB9+OGH+X5yU1KqV6+ulStX6qOPPtLGjRu1YMEClSpVSnXq1LH9Xm90GkVhjmth25k7d67ef/99vfLKK8rOzlb9+vW1cOFCPfDAAwWuZ7VaVbduXZ05c0bNmze3K3v44YcVHR2tWbNmadCgQSpTpozq1aunRYsW2V3Q27VrV4WHh+c5c5vryy+/lHTlk46vvvoqT/mWLVuKbYrU9dSuXVtDhgzJM4WuKGPx2tfYwnByctK8efM0ffp0ffDBBzp37pyqVatm98VM17N161b5+/vn+ZQDdxaLcbuu3ADwl7Rw4ULFxMTYpg3g5vj4+Ojll19WZGRkSXflhgwbNkzdunWzC2ZwTDt37tTnn39u982TuDUuXbqkFi1aaPLkycV6bQxuP24rB+CmdOvWTdnZ2bYLqHD3OXjwoH788ccizzfG7ZOTk6NZs2apZcuWJd2Vu8KKFStktVpv6NMHOCYCM4Cb4uLioilTpmjatGlFupsB7nyenp5avHjxTU/xwa3n5OSkkSNHcrbzNvjjjz/04YcfatKkSXz69hfAlAwAAADABGeYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATBCYAQAAABMEZgAAAMAEgRkAAAAwQWAGAAAATBCYAQAAABP/D0UZh2/glAoCAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='class', data=df, palette='muted')\n",
    "plt.title('Distribution of Comments')\n",
    "plt.xlabel('Annotation (0 = Hate Speech, 1 = Offensive, 2 = Neither)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "tdf, df = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_content</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28100</th>\n",
       "      <td>whiteponyjr lmaoooo what a bunch of fag</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38877</th>\n",
       "      <td>i know i hate fat loud bitch</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31483</th>\n",
       "      <td>i hate all these industry fag i hope they all ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1689</th>\n",
       "      <td>it is so wonderful when you meet a dude that i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18056</th>\n",
       "      <td>whenrappersaids when tupac said i are not a ki...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5042</th>\n",
       "      <td>mite hit the rec i know cell marcus and try to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46641</th>\n",
       "      <td>oreo ice cream cake</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27089</th>\n",
       "      <td>bitch think it is their time to prosper</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47233</th>\n",
       "      <td>that1guyjeff rebeccaisfresh carrot cake is tra...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15267</th>\n",
       "      <td>madd gay cirocbwoy teacher giving nigga pussy ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11514 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       processed_content  class\n",
       "28100            whiteponyjr lmaoooo what a bunch of fag      0\n",
       "38877                       i know i hate fat loud bitch      0\n",
       "31483  i hate all these industry fag i hope they all ...      0\n",
       "1689   it is so wonderful when you meet a dude that i...      1\n",
       "18056  whenrappersaids when tupac said i are not a ki...      1\n",
       "...                                                  ...    ...\n",
       "5042   mite hit the rec i know cell marcus and try to...      1\n",
       "46641                                oreo ice cream cake      2\n",
       "27089            bitch think it is their time to prosper      0\n",
       "47233  that1guyjeff rebeccaisfresh carrot cake is tra...      2\n",
       "15267  madd gay cirocbwoy teacher giving nigga pussy ...      1\n",
       "\n",
       "[11514 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 126\u001b[0m\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, tdf, df\n\u001b[0;32m    125\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m--> 126\u001b[0m model, tdf, df \u001b[38;5;241m=\u001b[39m train_model(tdf, df)\n",
      "Cell \u001b[1;32mIn[67], line 45\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(tdf, df)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# Prepare tokenizer and model\u001b[39;00m\n\u001b[0;32m     41\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m DistilBertTokenizerFast\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m DistilBertForSequenceClassification\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistilbert-base-uncased\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m     44\u001b[0m     num_labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# 3 classes\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Prepare datasets\u001b[39;00m\n\u001b[0;32m     48\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m NLPDataset(tdf, tokenizer)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\modeling_utils.py:3164\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3159\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[0;32m   3160\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   3161\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3162\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   3163\u001b[0m         )\n\u001b[1;32m-> 3164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(convert)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[0;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[1;32m--> 900\u001b[0m         module\u001b[38;5;241m.\u001b[39m_apply(fn)\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[0;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[0;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[0;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[1;34m(self, fn, recurse)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[0;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m fn(param)\n\u001b[0;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[0;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[0;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1321\u001b[0m             device,\n\u001b[0;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1323\u001b[0m             non_blocking,\n\u001b[0;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[0;32m   1325\u001b[0m         )\n\u001b[1;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[0;32m   1327\u001b[0m         device,\n\u001b[0;32m   1328\u001b[0m         dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1329\u001b[0m         non_blocking,\n\u001b[0;32m   1330\u001b[0m     )\n\u001b[0;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NLPDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
    "        self.texts = dataframe['processed_content'].tolist()\n",
    "        self.labels = dataframe['class'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def train_model(tdf, df):\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Prepare tokenizer and model\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        'distilbert-base-uncased', \n",
    "        num_labels=3  # 3 classes\n",
    "    ).to(device)\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = NLPDataset(tdf, tokenizer)\n",
    "    test_dataset = NLPDataset(df, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    # Prepare optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.0004)\n",
    "    total_steps = len(train_dataloader) * 10\n",
    "    warmup_steps = int(total_steps * 0.1)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=warmup_steps, \n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/10')\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids, \n",
    "                attention_mask=attention_mask, \n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        print(f'Epoch {epoch+1} Average Loss: {epoch_loss/len(train_dataloader)}')\n",
    "\n",
    "    # Generate embeddings\n",
    "    model.eval()\n",
    "    \n",
    "    def generate_embeddings(dataframe):\n",
    "        embeddings = []\n",
    "        dataset = NLPDataset(dataframe, tokenizer)\n",
    "        dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc='Generating Embeddings'):\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "                \n",
    "                # Use the last hidden state's mean as embedding\n",
    "                batch_embeddings = outputs.hidden_states[-1][:, 0, :].cpu().numpy()\n",
    "                embeddings.extend(batch_embeddings)\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    # Generate and add embeddings to both dataframes\n",
    "    tdf['bert_embeddings'] = generate_embeddings(tdf)\n",
    "    df['bert_embeddings'] = generate_embeddings(df)\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    model.save_pretrained('./finetuned_distilbert_model')\n",
    "    tokenizer.save_pretrained('./finetuned_distilbert_model')\n",
    "\n",
    "    return model, tdf, df\n",
    "\n",
    "# Usage\n",
    "model, tdf, df = train_model(tdf, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU for training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\dasad\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23bcfae3e5ed4d84adbd12408e10ece1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1/10:   0%|          | 0/2879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Average Loss: 0.5330220664184658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "287da802dc24459886a96a58c6548070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2/10:   0%|          | 0/2879 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 125\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model, tdf, df\n\u001b[0;32m    124\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m--> 125\u001b[0m model, tdf, df \u001b[38;5;241m=\u001b[39m train_model(tdf, df)\n",
      "Cell \u001b[1;32mIn[68], line 76\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(tdf, df)\u001b[0m\n\u001b[0;32m     73\u001b[0m attention_mask \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     74\u001b[0m labels \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 76\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\n\u001b[0;32m     77\u001b[0m     input_ids, \n\u001b[0;32m     78\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask, \n\u001b[0;32m     79\u001b[0m     labels\u001b[38;5;241m=\u001b[39mlabels\n\u001b[0;32m     80\u001b[0m )\n\u001b[0;32m     82\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[0;32m     83\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:978\u001b[0m, in \u001b[0;36mDistilBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    971\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m    974\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m    975\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    976\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m--> 978\u001b[0m distilbert_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistilbert(\n\u001b[0;32m    979\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[0;32m    980\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    981\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    982\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[0;32m    983\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    984\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    985\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    986\u001b[0m )\n\u001b[0;32m    987\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m distilbert_output[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, seq_len, dim)\u001b[39;00m\n\u001b[0;32m    988\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m hidden_state[:, \u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# (bs, dim)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:798\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_sdpa \u001b[38;5;129;01mand\u001b[39;00m head_mask_is_none \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_attentions:\n\u001b[0;32m    794\u001b[0m         attention_mask \u001b[38;5;241m=\u001b[39m _prepare_4d_attention_mask_for_sdpa(\n\u001b[0;32m    795\u001b[0m             attention_mask, embeddings\u001b[38;5;241m.\u001b[39mdtype, tgt_len\u001b[38;5;241m=\u001b[39minput_shape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    796\u001b[0m         )\n\u001b[1;32m--> 798\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer(\n\u001b[0;32m    799\u001b[0m     x\u001b[38;5;241m=\u001b[39membeddings,\n\u001b[0;32m    800\u001b[0m     attn_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[0;32m    801\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[0;32m    802\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[0;32m    803\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[0;32m    804\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[0;32m    805\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:551\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    543\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    544\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    545\u001b[0m         hidden_state,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    548\u001b[0m         output_attentions,\n\u001b[0;32m    549\u001b[0m     )\n\u001b[0;32m    550\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 551\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m layer_module(\n\u001b[0;32m    552\u001b[0m         hidden_state,\n\u001b[0;32m    553\u001b[0m         attn_mask,\n\u001b[0;32m    554\u001b[0m         head_mask[i],\n\u001b[0;32m    555\u001b[0m         output_attentions,\n\u001b[0;32m    556\u001b[0m     )\n\u001b[0;32m    558\u001b[0m hidden_state \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:495\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[1;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[0;32m    492\u001b[0m sa_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msa_layer_norm(sa_output \u001b[38;5;241m+\u001b[39m x)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;66;03m# Feed Forward Network\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m ffn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    496\u001b[0m ffn_output: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer_norm(ffn_output \u001b[38;5;241m+\u001b[39m sa_output)  \u001b[38;5;66;03m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m    498\u001b[0m output \u001b[38;5;241m=\u001b[39m (ffn_output,)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:429\u001b[0m, in \u001b[0;36mFFN.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    428\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 429\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m apply_chunking_to_forward(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mff_chunk, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchunk_size_feed_forward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseq_len_dim, \u001b[38;5;28minput\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\pytorch_utils.py:256\u001b[0m, in \u001b[0;36mapply_chunking_to_forward\u001b[1;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[0;32m    254\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(output_chunks, dim\u001b[38;5;241m=\u001b[39mchunk_dim)\n\u001b[1;32m--> 256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m forward_fn(\u001b[38;5;241m*\u001b[39minput_tensors)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py:432\u001b[0m, in \u001b[0;36mFFN.ff_chunk\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    431\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mff_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 432\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(\u001b[38;5;28minput\u001b[39m)\n\u001b[0;32m    433\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(x)\n\u001b[0;32m    434\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast, AdamW, get_linear_schedule_with_warmup\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class NLPDataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
    "        self.texts = dataframe['processed_content'].tolist()\n",
    "        self.labels = dataframe['class'].tolist()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].flatten(),\n",
    "            'attention_mask': inputs['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def train_model(tdf, df):\n",
    "    # Use CPU\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU for training\")\n",
    "\n",
    "    # Prepare tokenizer and model\n",
    "    tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "    model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        'distilbert-base-uncased', \n",
    "        num_labels=3  # 3 classes\n",
    "    )\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = NLPDataset(tdf, tokenizer)\n",
    "    test_dataset = NLPDataset(df, tokenizer)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    \n",
    "    # Prepare optimizer and scheduler\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.0004)\n",
    "    total_steps = len(train_dataloader) * 10\n",
    "    warmup_steps = int(total_steps * 0.1)\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, \n",
    "        num_warmup_steps=warmup_steps, \n",
    "        num_training_steps=total_steps\n",
    "    )\n",
    "\n",
    "    # Training loop\n",
    "    model.train()\n",
    "    for epoch in range(10):\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm(train_dataloader, desc=f'Epoch {epoch+1}/10')\n",
    "        \n",
    "        for batch in progress_bar:\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            input_ids = batch['input_ids']\n",
    "            attention_mask = batch['attention_mask']\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            outputs = model(\n",
    "                input_ids, \n",
    "                attention_mask=attention_mask, \n",
    "                labels=labels\n",
    "            )\n",
    "            \n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            \n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        print(f'Epoch {epoch+1} Average Loss: {epoch_loss/len(train_dataloader)}')\n",
    "\n",
    "    # Generate embeddings\n",
    "    def generate_embeddings(dataframe):\n",
    "        embeddings = []\n",
    "        dataset = NLPDataset(dataframe, tokenizer)\n",
    "        dataloader = DataLoader(dataset, batch_size=16, shuffle=False)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(dataloader, desc='Generating Embeddings'):\n",
    "                input_ids = batch['input_ids']\n",
    "                attention_mask = batch['attention_mask']\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask=attention_mask, output_hidden_states=True)\n",
    "                \n",
    "                # Use the last hidden state's mean as embedding\n",
    "                batch_embeddings = outputs.hidden_states[-1][:, 0, :].numpy()\n",
    "                embeddings.extend(batch_embeddings)\n",
    "        \n",
    "        return embeddings\n",
    "\n",
    "    # Generate and add embeddings to both dataframes\n",
    "    tdf['bert_embeddings'] = generate_embeddings(tdf)\n",
    "    df['bert_embeddings'] = generate_embeddings(df)\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    model.save_pretrained('./finetuned_distilbert_model')\n",
    "    tokenizer.save_pretrained('./finetuned_distilbert_model')\n",
    "\n",
    "    return model, tdf, df\n",
    "\n",
    "# Usage\n",
    "model, tdf, df = train_model(tdf, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
