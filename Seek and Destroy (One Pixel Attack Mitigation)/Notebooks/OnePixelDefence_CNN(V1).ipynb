{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VsKl8F0QDtel"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "import torchvision.transforms as transforms\n",
        "from tqdm import tqdm\n",
        "from scipy.optimize import differential_evolution\n",
        "from scipy import stats\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "dataset_path = 'dog-breeds'\n",
        "dataset = ImageFolder(root=dataset_path, transform=transform)\n",
        "train_loader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=0, pin_memory=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "w0O2btuzD8c2"
      },
      "outputs": [],
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(128 * 16 * 16, 256)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "class CoordinateCNN(nn.Module):\n",
        "    def __init__(self, input_channels, image_height, image_width):\n",
        "        super(CoordinateCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(64)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.pooled_height = image_height // 8\n",
        "        self.pooled_width = image_width // 8\n",
        "        self.fc1 = nn.Linear(128 * self.pooled_height * self.pooled_width, 256)\n",
        "        self.fc2 = nn.Linear(256, 2)  # Output for pixel coordinates (x, y)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x) \n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "WKYQapGSD-DR"
      },
      "outputs": [],
      "source": [
        "def train_and_validate(model, train_loader, num_epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}\")\n",
        "        scheduler.step(epoch_loss)\n",
        "\n",
        "\n",
        "    \n",
        "def test_model(model, dataset):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in DataLoader(dataset, batch_size=64, shuffle=False, num_workers=0, pin_memory=True):\n",
        "            if len(batch) == 3:  \n",
        "                inputs, labels, _ = batch\n",
        "            else:  \n",
        "                inputs, labels = batch\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "    accuracy = correct / total\n",
        "    print(f'Test Accuracy: {accuracy:.4f}')\n",
        "\n",
        "def train_coordinate_model(model, optimizer, attacked_loader, num_epochs=10):\n",
        "    criterion = nn.MSELoss()\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for images, _, coords in tqdm(attacked_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\"):\n",
        "            images, coords = images.to(device), coords.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, coords)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(attacked_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
        "        scheduler.step(epoch_loss)\n",
        "\n",
        "def train_with_amp(model, train_loader, num_epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3)\n",
        "    scaler = torch.cuda.amp.GradScaler()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} [Training]\"):\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.cuda.amp.autocast():\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {epoch_loss:.4f}\")\n",
        "        scheduler.step(epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8mRYY_keD_rH"
      },
      "outputs": [],
      "source": [
        "# One-pixel attack dataset\n",
        "class OnePixelAttackDataset(Dataset):\n",
        "    def __init__(self, dataset, model):\n",
        "        self.dataset = dataset\n",
        "        self.model = model\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.dataset[idx]\n",
        "        img = img.cuda()\n",
        "        img_np = np.array(img.permute(1, 2, 0).cpu()).copy()  \n",
        "\n",
        "        def attack_one_pixel(p):\n",
        "            x, y, r, g, b = int(p[0]), int(p[1]), int(p[2]), int(p[3]), int(p[4])\n",
        "            attacked_img = img_np.copy()\n",
        "            attacked_img[x, y] = [r, g, b]\n",
        "            attacked_img = torch.from_numpy(attacked_img.transpose(2, 0, 1)).float().cuda()\n",
        "            output = self.model(attacked_img.unsqueeze(0))\n",
        "            return -F.softmax(output, dim=1)[0][label].item()\n",
        "\n",
        "        bounds = [(0, img_np.shape[0] - 1), (0, img_np.shape[1] - 1), (0, 255), (0, 255), (0, 255)]\n",
        "        result = differential_evolution(attack_one_pixel, bounds)\n",
        "        x, y, r, g, b = map(int, result.x)\n",
        "        img_np[x, y] = [r, g, b]\n",
        "\n",
        "        img_np = img_np.transpose(2, 0, 1)  # Convert back to CHW format\n",
        "        attacked_img = torch.from_numpy(img_np).float() / 255\n",
        "\n",
        "        return attacked_img, label, torch.tensor([x, y], dtype=torch.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6Lq8XjZkEYMv"
      },
      "outputs": [],
      "source": [
        "class RepairedDataset(Dataset):\n",
        "    def __init__(self, attacked_dataset, coordinate_model, patch_size=5):\n",
        "        self.attacked_dataset = attacked_dataset\n",
        "        self.coordinate_model = coordinate_model\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.attacked_dataset)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label, _ = self.attacked_dataset[idx]\n",
        "        img_tensor = img.unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            predicted_coords = self.coordinate_model(img_tensor).squeeze()\n",
        "\n",
        "        x, y = predicted_coords.int().tolist()\n",
        "        img_np = img.permute(1, 2, 0).cpu().numpy()  \n",
        "\n",
        "        x_start = max(0, x - self.patch_size // 2)\n",
        "        x_end = min(img_np.shape[0], x + self.patch_size // 2 + 1)\n",
        "        y_start = max(0, y - self.patch_size // 2)\n",
        "        y_end = min(img_np.shape[1], y + self.patch_size // 2 + 1)\n",
        "\n",
        "        patch = img_np[x_start:x_end, y_start:y_end]\n",
        "\n",
        "        mode_values = stats.mode(patch.reshape(-1, 3), axis=0).mode[0]\n",
        "\n",
        "        img_np[x_start:x_end, y_start:y_end] = mode_values\n",
        "\n",
        "        repaired_img = torch.from_numpy(img_np.transpose(2, 0, 1)).float()\n",
        "        return repaired_img, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSkldpZhEax9",
        "outputId": "3f87e399-1a45-4533-b575-fb415071acd2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10 [Training]: 100%|██████████| 31/31 [00:09<00:00,  3.43it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Training Loss: 7.3359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10 [Training]: 100%|██████████| 31/31 [00:01<00:00, 15.98it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/10, Training Loss: 0.9255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10 [Training]: 100%|██████████| 31/31 [00:02<00:00, 15.00it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/10, Training Loss: 0.2038\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10 [Training]: 100%|██████████| 31/31 [00:02<00:00, 14.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/10, Training Loss: 0.0612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10 [Training]: 100%|██████████| 31/31 [00:02<00:00, 14.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/10, Training Loss: 0.0284\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10 [Training]: 100%|██████████| 31/31 [00:02<00:00, 14.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/10, Training Loss: 0.0168\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10 [Training]: 100%|██████████| 31/31 [00:02<00:00, 14.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/10, Training Loss: 0.0095\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10 [Training]: 100%|██████████| 31/31 [00:02<00:00, 14.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/10, Training Loss: 0.0056\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10 [Training]: 100%|██████████| 31/31 [00:01<00:00, 16.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/10, Training Loss: 0.0042\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10 [Training]: 100%|██████████| 31/31 [00:01<00:00, 16.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/10, Training Loss: 0.0030\n",
            "Testing original model:\n",
            "Test Accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "num_classes = len(dataset.classes)\n",
        "cnn_model = SimpleCNN(num_classes).to(device)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    train_with_amp(cnn_model, train_loader)\n",
        "else:\n",
        "    train_and_validate(cnn_model, train_loader)\n",
        "\n",
        "# Test the model\n",
        "print(\"Testing original model:\")\n",
        "test_model(cnn_model, dataset)\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "r4IbpFHUEhSS"
      },
      "outputs": [],
      "source": [
        "cnn_model.eval()\n",
        "attacked_dataset = OnePixelAttackDataset(dataset, cnn_model)\n",
        "attacked_loader = DataLoader(attacked_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "Bwl8xLFgElHY",
        "outputId": "de2aee6b-2515-487b-b506-05547f4b2fa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing attacked dataset:\n"
          ]
        }
      ],
      "source": [
        "print(\"Testing attacked dataset:\")\n",
        "test_model(cnn_model, attacked_dataset)\n",
        "\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MonosQtBEmY2"
      },
      "outputs": [],
      "source": [
        "coordinate_model = CoordinateCNN(input_channels=3, image_height=128, image_width=128).to(device)\n",
        "optimizer = torch.optim.Adam(coordinate_model.parameters(), lr=0.001)\n",
        "train_coordinate_model(coordinate_model, optimizer, attacked_loader)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJbI7oQIEoi-"
      },
      "outputs": [],
      "source": [
        "repaired_dataset = RepairedDataset(attacked_dataset, coordinate_model, patch_size=5)\n",
        "repaired_loader = DataLoader(repaired_dataset, batch_size=32, shuffle=False, num_workers=0, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OJI07yqeEqnF"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"Testing repaired dataset:\")\n",
        "test_model(cnn_model, repaired_dataset)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
